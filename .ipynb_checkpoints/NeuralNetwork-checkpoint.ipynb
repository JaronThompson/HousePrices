{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from platform import python_version\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchcontrib.optim import SWA\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "# import preprocessing tools \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression as mi\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.8.3\n",
      "pandas==1.1.4\n",
      "numpy==1.18.5\n",
      "sklearn==0.23.1\n",
      "torch==1.7.0\n",
      "matplotlib==3.2.2\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)\n",
    "\n",
    "plt.rcParams[\n",
    "    \"figure.facecolor\"\n",
    "] = \"w\"  # force white background on plots when using dark mode in JupyterLab\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'data_description.txt', 'house-prices-advanced-regression-techniques.zip', 'train.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "0   1          60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
       "1   2          20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "2   3          60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
       "3   4          70       RL     9550   Pave      IR1         Lvl    AllPub   \n",
       "4   5          60       RL    14260   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "  LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch PoolArea  \\\n",
       "0    Inside       Gtl  ...             0         0           0        0   \n",
       "1       FR2       Gtl  ...             0         0           0        0   \n",
       "2    Inside       Gtl  ...             0         0           0        0   \n",
       "3    Corner       Gtl  ...           272         0           0        0   \n",
       "4       FR2       Gtl  ...             0         0           0        0   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    208500  \n",
       "1       0       5    2007        WD         Normal    181500  \n",
       "2       0       9    2008        WD         Normal    223500  \n",
       "3       0       2    2006        WD        Abnorml    140000  \n",
       "4       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.listdir('DATA'))\n",
    "\n",
    "train = pd.read_csv(\"DATA/train.csv\").dropna(axis=1)\n",
    "test = pd.read_csv(\"DATA/test.csv\")\n",
    "\n",
    "target = np.array(train['SalePrice'].values, np.float)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood is an important categorical, nominal feature \n",
    "# want to do the ordinal encoding manually \n",
    "def OrdinalEncoder(df, features, target='SalePrice'):\n",
    "    # loop through all categorical features \n",
    "    for feature in features:\n",
    "        neighborhoods = df[feature].values\n",
    "        prices = []\n",
    "        # for each feature, determine avg target value\n",
    "        for neighborhood in np.unique(neighborhoods):\n",
    "            inds = neighborhood == neighborhoods\n",
    "            prices.append(np.mean(df.iloc[inds, :][target].values))\n",
    "        ordinal_labels = np.argsort(prices)\n",
    "        prices_dict = {neighborhood:i for i, neighborhood in enumerate(np.unique(neighborhoods)[ordinal_labels])}\n",
    "        # encode categorical features ordinally based on target values \n",
    "        encoded_neighborhood = [prices_dict[n] for n in neighborhoods]\n",
    "        df[feature] = encoded_neighborhood\n",
    "    return df\n",
    "\n",
    "# pull out categorical and continuous features \n",
    "continuousfeatures = train.describe().columns.values[1:-1] \n",
    "categoricalfeatures = [ftr for ftr in train.columns.values[1:-1] if ftr not in continuousfeatures]\n",
    "features = list(continuousfeatures) + categoricalfeatures\n",
    "\n",
    "# Assume categorical features are ordinal and encode \n",
    "train = OrdinalEncoder(train, categoricalfeatures)\n",
    "\n",
    "# take decades since 2020 for features that describe the year \n",
    "yearfeatures = [f for f in features if 'Year' in f or 'Yr' in f]\n",
    "train[yearfeatures] = (2020 - train[yearfeatures].values)/ 10\n",
    "\n",
    "# take square root of features that describe area and divide by max \n",
    "areafeatures = [f for f in features if 'SF' in f or 'Area' in f]\n",
    "train[areafeatures] = train[areafeatures].values**.5 / np.max(train[areafeatures].values**.5, 0)\n",
    "\n",
    "# set up training data \n",
    "X = np.array(train[features].values, np.float)\n",
    "y = np.array(train['SalePrice'].values, np.float)\n",
    "\n",
    "# center data \n",
    "X = MinMaxScaler((-1, 1)).fit(X).transform(X)\n",
    "\n",
    "# actually predict centered log_y \n",
    "y = np.log(y) - np.mean(np.log(y)) \n",
    "\n",
    "# set up a dataframe with features and target variables \n",
    "train[features] = X \n",
    "train['SalePrice'] = y\n",
    "X_df = train[features]\n",
    "y_df = train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset class for use with pytorch dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_df, y_df):\n",
    "        # set up dataframe\n",
    "        self.X_df = X_df\n",
    "        self.y_df = y_df\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # load X \n",
    "        features = self.X_df.values[index]\n",
    "        x = torch.tensor(features, dtype=torch.float32)\n",
    "        \n",
    "        # load noisey y \n",
    "        target = self.y_df.values[index]\n",
    "        y = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        # total size of your dataset.\n",
    "        return len(self.X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, h_dim, out_dim=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size  = in_dim\n",
    "        self.hidden_size = h_dim\n",
    "        self.output_size = out_dim\n",
    "        \n",
    "        # define first fully connected layer \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        \n",
    "        # define optional second fully connected layer \n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        # add activation \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # define fully connected hidden layer \n",
    "        self.output = nn.Linear(self.hidden_size, self.output_size)    \n",
    "        \n",
    "    def forward(self, out):\n",
    "        out = self.fc1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNtrain(model, swa_model, trainloader, valloader, optimizer, criterion, num_epochs=300, patience=15, verbose=True, path_to_model='model.ckpt'): \n",
    "    # set up scheduler to reduce learning rate \n",
    "    min_lr = 1e-5\n",
    "    scheduler = ReduceLROnPlateau(optimizer=optimizer, min_lr=min_lr, mode='min', patience=0, verbose=True)\n",
    "    best_val = np.inf\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # set up model for training     \n",
    "        model.train()\n",
    "        for i, (x, y) in enumerate(trainloader):\n",
    "\n",
    "            # send data to gpu or cpu RAM \n",
    "            # input has dimensions (sequence length, batch size, n inputs)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(x)\n",
    "            \n",
    "            # reshape targets to match output\n",
    "            y = torch.reshape(y, [y.shape[0], 1])\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Compute loss \n",
    "            loss = criterion(output, y) \n",
    "            # Backward pass\n",
    "            loss.backward()       \n",
    "            # Optimizer step\n",
    "            optimizer.step()                        \n",
    "            # Reset gradients   \n",
    "            model.zero_grad() \n",
    "            \n",
    "\n",
    "        # Evaluate validation data at end of each epoch\n",
    "        valid_predictions = []\n",
    "        valid_targets = []\n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(valloader):\n",
    "                x = x.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(x)\n",
    "\n",
    "                # reshape targets to match output\n",
    "                y = torch.reshape(y, [y.shape[0], 1])\n",
    "                y = y.to(device)\n",
    "\n",
    "                # Store predictions and true values \n",
    "                valid_predictions += list(output.detach().cpu().numpy())\n",
    "                valid_targets += list(y.cpu().numpy())\n",
    "\n",
    "        # Calculate performance statistics on validation data \n",
    "        val_rmse = np.linalg.norm(np.array(valid_predictions) - np.array(valid_targets))/len(np.array(valid_targets))\n",
    "\n",
    "        # learning rate is reduced if val roc doesn't improve \n",
    "        scheduler.step(val_rmse)\n",
    "        \n",
    "        # start averaging weights at min learning rate\n",
    "        if optimizer.param_groups[0]['lr'] == min_lr:\n",
    "            swa_model.update_parameters(model)\n",
    "        \n",
    "        # Save model if validation performance improved \n",
    "        if val_rmse <= best_val:\n",
    "            best_val = val_rmse  \n",
    "            print(\"Saving model... Epoch [{}/{}], Val RMSE: {:.3f}\\n\".format(epoch+1, num_epochs, val_rmse))\n",
    "            swa_model.update_parameters(model)\n",
    "            torch.save(swa_model.state_dict(), path_to_model)  \n",
    "        else:\n",
    "            # if performance doesn't improve, lose some patience \n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print('Early stopping. Best validation RMSE: {:.3f}'.format(best_val))\n",
    "                break\n",
    "\n",
    "    # Load best model from fold (in case last epoch was not best)\n",
    "    swa_model.load_state_dict(torch.load(path_to_model))\n",
    "        \n",
    "    '''if epoch > 30:\n",
    "        return swa_model, True\n",
    "    else:\n",
    "        return swa_model, False'''\n",
    "    return swa_model, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model... Epoch [1/150], Val RMSE: 0.012\n",
      "\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Saving model... Epoch [3/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [4/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [5/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [6/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [7/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [8/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [9/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [10/150], Val RMSE: 0.011\n",
      "\n",
      "Saving model... Epoch [11/150], Val RMSE: 0.011\n",
      "\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8b5ef6127cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m### train nn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b005303f037b>\u001b[0m in \u001b[0;36mNNtrain\u001b[0;34m(model, swa_model, trainloader, valloader, optimizer, criterion, num_epochs, patience, verbose, path_to_model)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set up training params\n",
    "num_epochs = 150\n",
    "n_splits_1 = 24\n",
    "n_splits_2 = 6\n",
    "\n",
    "# set up out of fold predictions\n",
    "oof = np.zeros(len(X_df))\n",
    "\n",
    "# split data into 10 train+validation and testing data sets\n",
    "skf1 = KFold(n_splits=n_splits_1, shuffle=True, random_state=123)\n",
    "skf1.get_n_splits(X_df, y_df)\n",
    "for trainval_index, test_index in skf1.split(X_df):\n",
    "    # split the whole dataset into training+validation data and testing sets\n",
    "    X_trainval, X_test = X_df.iloc[trainval_index], X_df.iloc[test_index]\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_trainval, y_test = y_df.iloc[trainval_index], y_df.iloc[test_index]\n",
    "    \n",
    "    skf2 = KFold(n_splits=n_splits_2, shuffle=True, random_state=123)\n",
    "    skf2.get_n_splits(X_trainval, y_trainval)\n",
    "    y_pred_test = 0\n",
    "    n_converged = 0\n",
    "    for train_index, val_index in skf2.split(X_trainval):\n",
    "        X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[val_index]\n",
    "        y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[val_index]\n",
    "    \n",
    "        # initialize the data set \n",
    "        train_dataset = Dataset(X_train, y_train)                                              \n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32) \n",
    "        val_dataset  = Dataset(X_val, y_val)\n",
    "        val_loader   = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=32)\n",
    "\n",
    "        # initialize model \n",
    "        model = Model(in_dim=len(features), h_dim=32, out_dim=1).to(device)\n",
    "\n",
    "        # define lr and optimizer \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "        swa_model = AveragedModel(model)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        ### train nn\n",
    "        model, converged = NNtrain(model, swa_model, train_loader, val_loader, optimizer, criterion, num_epochs, verbose=True)\n",
    "\n",
    "        # make predictions \n",
    "        if converged:\n",
    "            y_pred_test += model(X_test).detach().cpu().numpy().flatten() \n",
    "            n_converged += 1\n",
    "    y_pred_test /= n_converged\n",
    "    \n",
    "    # store predictions\n",
    "    oof[test_index] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance\n",
    "rmse = np.linalg.norm(y - oof)/len(y)\n",
    "R2 = r2_score(y, oof)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.scatter(oof, y, alpha=.6, label=\"NN, RMSE: {:.5f}, R2: {:.5f}\".format(rmse, R2))\n",
    "plt.xlabel(\"Predicted house price\", fontsize=16)\n",
    "plt.ylabel(\"True house price\", fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Neural network\", fontsize=18)\n",
    "plt.savefig(\"Figures/NeuralNetwork.png\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
